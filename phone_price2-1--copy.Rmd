---
title: "Classification for phone prices"
author: "XIAO MA, HAO ZHENG, YONGZI YU"
date: "05/09/2022"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  fig.height = 8,
  fig.width = 12,
  dpi = 200, 
  message = F,
  echo = T,
  warning = F,
  cache = T
)
# theme_set(theme_minimal() + theme(
#   legend.position = "bottom",
#   plot.title = element_text(hjust = 0.5)
# ))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis",
  digits = 3
)
# scale_colour_discrete = scale_colour_viridis_d
# scale_fill_discrete = scale_fill_viridis_d
```


```{r}
# library(reticulate)
library(caret)
library(tidyverse)
library(ggpubr)
library(doParallel)
library(ranger)
library(pROC)
library(gbm)
library(pdp)
library(lime)
library(cutpointr)
```

```{r}
# read data
df = read.csv("data/train.csv")

# covert outcome to binary
df$price_range = as.factor(ifelse(df$price_range >=2, "High", "Low"))

# convert data format
df = df %>% 
    mutate_at(vars("blue", "dual_sim", "four_g", "three_g", "touch_screen", "wifi"), 
              ~factor(., levels = c(0, 1), labels = c("No", "Yes")))
```


```{r data_preprocess}
# split into training set
set.seed(1)
train_index = createDataPartition(df$price_range,p=0.8,list = F)
train_df = df[train_index, ]
test_df = df[-train_index, ]
```


```{r}
# user parallel to accelarate 
cl <- makePSOCKcluster(4)
registerDoParallel(cl)
```


## Bagging

```{r }
ctrl <- trainControl(method = "cv", classProbs = TRUE, 
                     summaryFunction = twoClassSummary) 

bagging.grid <- expand.grid(mtry = 20, 
                       splitrule = "gini",
                       min.node.size = seq(from = 2, to = 10, by = 2))
set.seed(1) 
bagging.fit <- train(price_range ~ . , 
                df, 
                subset = train_index, 
                tuneGrid = bagging.grid, 
                method = "ranger",
                metric = "ROC",
                trControl = ctrl)
```

```{r}
ggplot(bagging.fit, highlight = TRUE)
```

## Random forest

```{r }
ctrl <- trainControl(method = "cv", classProbs = TRUE, 
                     summaryFunction = twoClassSummary) 

rf.grid <- expand.grid(mtry = 1:8, 
                       splitrule = "gini",
                       min.node.size = seq(from = 2, to = 10, by = 2))
set.seed(1) 
rf.fit <- train(price_range ~ . , 
                df, 
                subset = train_index, 
                tuneGrid = rf.grid, 
                method = "ranger",
                metric = "ROC",
                trControl = ctrl)
```


```{r}
ggplot(rf.fit, highlight = TRUE)
```

## AdaBoost

```{r }
gbm.grid <- expand.grid(n.trees = c(2000,3000,4000,5000), 
                        interaction.depth = 1:6, 
                        shrinkage = c(0.0005,0.001,0.002), 
                        n.minobsinnode = 1)
set.seed(1) 
gbm.fit <- train(price_range ~ . , 
                 df, 
                 subset = train_index, 
                 tuneGrid = gbm.grid, 
                 trControl = ctrl,
                 method = "gbm",
                 distribution = "adaboost",
                 metric = "ROC",
                 verbose = FALSE)
```


```{r}
ggplot(gbm.fit, highlight = TRUE)
```

## SVM

```{r }
set.seed(1)
svm.fit = train(price_range ~ . , 
                 df, 
                 subset = train_index, 
                method = "svmRadialCost",
                tuneGrid = data.frame(C = exp(seq(-3,3,len=20))),
                trControl = ctrl,
                metric = "ROC",
                prob.model = TRUE,
                 verbose = FALSE)
```


```{r}
plot(svm.fit)
```


## ROC camparison

```{r}
pred.bagging = predict(bagging.fit, newdata = df[-train_index, ], type = "prob")[,1]
roc.bagging = pROC::roc(df$price_range[-train_index], pred.bagging)
pred.rf = predict(rf.fit, newdata = df[-train_index, ], type = "prob")[,1]
roc.rf = pROC::roc(df$price_range[-train_index], pred.rf)
pred.gbm = predict(gbm.fit, newdata = df[-train_index, ], type = "prob")[,1]
roc.gbm = pROC::roc(df$price_range[-train_index], pred.gbm)
pred.svm = predict(svm.fit, newdata = df[-train_index, ], type = "prob")[,1]
roc.svm = pROC::roc(df$price_range[-train_index], pred.svm)

plot(roc.bagging, col = 1) 
plot(roc.rf, add = TRUE, col = 2)
plot(roc.gbm, add = TRUE, col = 3)
plot(roc.svm, add = TRUE, col = 4)
auc <- c(roc.bagging$auc[1], roc.rf$auc[1], roc.gbm$auc[1], roc.svm$auc[1])
modelNames <- c("Bagging", "RF","Adaboost", "SVM") 
legend("bottomright", 
       legend = paste0(modelNames, ": ", 
                       round(auc,3)), 
       col = 1:4, lwd = 2)
```


## Global Importance

```{r}
gbmImp <- varImp(gbm.fit, scale = TRUE)
plot(gbmImp, top = 10)
```


## LIME

```{r fig.height=18, fig.width=12}
explainer.rf <- lime(df[train_index, -21], gbm.fit)
new_obs = df[-train_index, -21][1:6, ]
explaination.obs = explain(new_obs, 
                           explainer = explainer.rf,
                           n_features = 10,
                           n_labels = 2)
plot_features(explaination.obs)
```

## Prediction error

```{r}
pred.gbm.train = predict(gbm.fit, newdata = df[train_index, ], type = "prob")[, 1]
train_df$pred.gbm = pred.gbm.train
cp <- cutpointr(train_df, pred.gbm, price_range, 
                method = maximize_metric, metric = sum_sens_spec)
summary(cp)
```

```{r}
test_df$pred.gbm = as.factor(ifelse(pred.gbm > cp$optimal_cutpoint, "High", "Low"))
cft = confusionMatrix(test_df$pred.gbm, test_df$price_range)
print(cft)
```

* In order to predict the high cost phone, we decided to build a binary classification model. We randomly divided our dataset into two data sets before training the classification algorithms: the training and the test sets. The training and test sets each included 80% and 20% of the total data, respectively. 

* The parameters of each algorithm were determined based on the classification performance of the training set as measured by five-fold cross-validation. On the test set, the performance of all algorithms was tested and compared. We evaluated and compared the results of five different algorithms since different classification methods are better suited to different types of data. Bagging, random forest, ada boosting, and radical kernel SVM are among the models under consideration.

* We plotted the ROC curves of all the different algorithms on the test dataset. Over all reasonable sensitivity thresholds and recall thresholds, the ada boosting model is consistently better than all the other models. The feature importance of the ADA boosting model is scaled between 0 and 100. Random access memory (RAM) is the most important predictor. Battery power is 20% as important as RAM. Pixel height and pixel width are each around 10% as important as RAM. All the other predictors are less than 5% as important as RAM.

* For the first six test cases and label combinations, we utilized LIME to visually represent the explanations. Positively associated features are displayed in blue, while negatively correlated features are displayed in red. We can observe that all of the predictors for the phone pricing outcome selected the same features, showing that these are important features both locally and globally.

* We selected to maximize the sum of sensitivity and specificity in order to determine the best cut point for the prediction probability. On the training dataset, the best cut point is `r cp$optimal_cutpoint`, which yields an accuracy of `r cp$acc`, a sensitivity of `r cp$sensitivity`, and a specificity of `r cp$specificity`. On the test dataset, we have an accuracy of `r cft$overall[1]`, sensitivity of `r cft$byClass[1]`, and specificity of `r cft$byClass[2]` using the optimal cut point. As a consequence, our model appears to be extremely effective in predicting high prices for phones.







